{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (C) 2025 Advanced Micro Devices, Inc. All rights reserved.\n",
    "Portions of this notebook consist of AI-generated content.\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "\n",
    "of this software and associated documentation files (the \"Software\"), to deal\n",
    "\n",
    "in the Software without restriction, including without limitation the rights\n",
    "\n",
    "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "\n",
    "copies of the Software, and to permit persons to whom the Software is\n",
    "\n",
    "furnished to do so, subject to the following conditions:\n",
    "\n",
    "\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all\n",
    "\n",
    "copies or substantial portions of the Software.\n",
    "\n",
    "\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "\n",
    "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "\n",
    "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "\n",
    "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "\n",
    "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "\n",
    "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "\n",
    "SOFTWARE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BYpymnyXiRfl"
   },
   "source": [
    "# CV03 Object Detection\n",
    "\n",
    "### Lab Description\n",
    "This laboratory exercise introduces **YOLOv9**, a state-of-the-art one-stage object detection model.  \n",
    "Unlike traditional detectors, YOLO (â€œYou Only Look Onceâ€) achieves high accuracy and speed by performing detection in a single forward pass, making it suitable for real-time applications.\n",
    "\n",
    "In this hands-on lab, you will:\n",
    "- **Train** YOLOv9 on a sample dataset for ~10 epochs.  \n",
    "- **Evaluate** the trained model on validation/test images.  \n",
    "- Record and visualize runtime, batch size, and GPU memory usage.  \n",
    "- Plot training curves to verify the learning process.\n",
    "\n",
    "### What you can expect to learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DZrgyMQSKtfy",
    "outputId": "2384877d-9888-469b-8cbe-ad0f0f680132"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ultralytics\n",
      "  Downloading ultralytics-8.3.205-py3-none-any.whl.metadata (37 kB)\n",
      "Requirement already satisfied: numpy>=1.23.0 in /home/aup/miniforge3/envs/dl_env/lib/python3.10/site-packages (from ultralytics) (2.2.6)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /home/aup/miniforge3/envs/dl_env/lib/python3.10/site-packages (from ultralytics) (3.10.5)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in /home/aup/miniforge3/envs/dl_env/lib/python3.10/site-packages (from ultralytics) (4.12.0.88)\n",
      "Requirement already satisfied: pillow>=7.1.2 in /home/aup/miniforge3/envs/dl_env/lib/python3.10/site-packages (from ultralytics) (11.3.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /home/aup/miniforge3/envs/dl_env/lib/python3.10/site-packages (from ultralytics) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.23.0 in /home/aup/miniforge3/envs/dl_env/lib/python3.10/site-packages (from ultralytics) (2.32.4)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /home/aup/miniforge3/envs/dl_env/lib/python3.10/site-packages (from ultralytics) (1.15.2)\n",
      "Requirement already satisfied: torch>=1.8.0 in /home/aup/miniforge3/envs/dl_env/lib/python3.10/site-packages (from ultralytics) (2.8.0+rocm6.4)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /home/aup/miniforge3/envs/dl_env/lib/python3.10/site-packages (from ultralytics) (0.23.0+rocm6.4)\n",
      "Requirement already satisfied: psutil in /home/aup/miniforge3/envs/dl_env/lib/python3.10/site-packages (from ultralytics) (7.0.0)\n",
      "Collecting polars (from ultralytics)\n",
      "  Downloading polars-1.34.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
      "  Downloading ultralytics_thop-2.0.17-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/aup/miniforge3/envs/dl_env/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/aup/miniforge3/envs/dl_env/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/aup/miniforge3/envs/dl_env/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (4.59.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/aup/miniforge3/envs/dl_env/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/aup/miniforge3/envs/dl_env/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/aup/miniforge3/envs/dl_env/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/aup/miniforge3/envs/dl_env/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /home/aup/miniforge3/envs/dl_env/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/aup/miniforge3/envs/dl_env/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/aup/miniforge3/envs/dl_env/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/aup/miniforge3/envs/dl_env/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/aup/miniforge3/envs/dl_env/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (2025.8.3)\n",
      "Requirement already satisfied: filelock in /home/aup/miniforge3/envs/dl_env/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/aup/miniforge3/envs/dl_env/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (4.14.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/aup/miniforge3/envs/dl_env/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (1.14.0)\n",
      "Requirement already satisfied: networkx in /home/aup/miniforge3/envs/dl_env/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/aup/miniforge3/envs/dl_env/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /home/aup/miniforge3/envs/dl_env/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (2025.7.0)\n",
      "Requirement already satisfied: pytorch-triton-rocm==3.4.0 in /home/aup/miniforge3/envs/dl_env/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.4.0)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /home/aup/miniforge3/envs/dl_env/lib/python3.10/site-packages (from pytorch-triton-rocm==3.4.0->torch>=1.8.0->ultralytics) (80.9.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/aup/miniforge3/envs/dl_env/lib/python3.10/site-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/aup/miniforge3/envs/dl_env/lib/python3.10/site-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
      "Collecting polars-runtime-32==1.34.0 (from polars->ultralytics)\n",
      "  Downloading polars_runtime_32-1.34.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Downloading ultralytics-8.3.205-py3-none-any.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m36m-:--:--\u001b[0m\n",
      "\u001b[?25hDownloading ultralytics_thop-2.0.17-py3-none-any.whl (28 kB)\n",
      "Downloading polars-1.34.0-py3-none-any.whl (772 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m772.7/772.7 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading polars_runtime_32-1.34.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (40.3 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m40.3/40.3 MB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: polars-runtime-32, polars, ultralytics-thop, ultralytics\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4/4\u001b[0m [ultralytics]\u001b[0m [ultralytics]\n",
      "\u001b[1A\u001b[2KSuccessfully installed polars-1.34.0 polars-runtime-32-1.34.0 ultralytics-8.3.205 ultralytics-thop-2.0.17\n"
     ]
    }
   ],
   "source": [
    "!pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6k0sRZzvXL4Z",
    "outputId": "106a48f4-d447-43a5-ad8e-42a44de2806a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU:4\n",
      "Python: 3.10.18\n",
      "PyTorch: 2.8.0+rocm6.4\n",
      "CUDA available: True\n",
      "CUDA device: AMD Radeon AI PRO R9700\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "\n",
    "print(\"Python:\", sys.version.split()[0])\n",
    "print(\"PyTorch:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA device:\", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Z82bt8jaK7ag"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new Ultralytics Settings v0.0.6 file âœ… \n",
      "View Ultralytics Settings with 'yolo settings' or at '/home/aup/.config/Ultralytics/settings.json'\n",
      "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kqNYLetIiyw1"
   },
   "source": [
    "## 2. Download COCO128 & Create Data YAML\n",
    "We use a **tiny COCO subset** (COCO128) so training finishes quickly.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CrMsxsZrM0We",
    "outputId": "23941d91-5957-4132-96e4-cc681432cf4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aup/data/YOLOv9_data\n"
     ]
    }
   ],
   "source": [
    "%cd /home/aup/data/YOLOv9_data\n",
    "!unzip -q Aerial.zip -d Aerial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IQoC1GTyi-xt"
   },
   "source": [
    "## 3. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0-Bsxyh2NJz4",
    "outputId": "217ba43a-fd21-4e8f-8f9e-9080137065ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov9c.pt to 'yolov9c.pt': 100% â”â”â”â”â”â”â”â”â”â”â”â” 49.4MB 12.2MB/s 4.1s.1s<0.0ss0s8\n"
     ]
    }
   ],
   "source": [
    "# Build a YOLOv9c model from pretrained weight\n",
    "model = YOLO(\"yolov9c.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YeA_l_9lNfbK",
    "outputId": "81c62ef7-bb44-45fb-8ed1-56cafbcc9585"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLOv9c summary: 358 layers, 25,590,912 parameters, 0 gradients, 104.0 GFLOPs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(358, 25590912, 0, 104.02268160000003)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MAoNdwo7Ngzx",
    "outputId": "04b6ed4a-4508-4b15-f9de-a21d53890f9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.205 ğŸš€ Python-3.10.18 torch-2.8.0+rocm6.4 CUDA:0 (AMD Radeon AI PRO R9700, 32624MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=4, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/home/aup/data/YOLOv9_data/Aerial/SkyFusion-YOLOv9/data.yaml, degrees=0.0, deterministic=True, device=4, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=10, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov9c.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/home/aup/data/YOLOv9_data/runs/detect/train, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/home/aup/.config/Ultralytics/Arial.ttf': 100% â”â”â”â”â”â”â”â”â”â”â”â” 755.1KB 956.5KB/s 0.8s.7s<0.2s2s\n",
      "Overriding model.yaml nc=80 with nc=3\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
      "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  2                  -1  1    212864  ultralytics.nn.modules.block.RepNCSPELAN4    [128, 256, 128, 64, 1]        \n",
      "  3                  -1  1    164352  ultralytics.nn.modules.block.ADown           [256, 256]                    \n",
      "  4                  -1  1    847616  ultralytics.nn.modules.block.RepNCSPELAN4    [256, 512, 256, 128, 1]       \n",
      "  5                  -1  1    656384  ultralytics.nn.modules.block.ADown           [512, 512]                    \n",
      "  6                  -1  1   2857472  ultralytics.nn.modules.block.RepNCSPELAN4    [512, 512, 512, 256, 1]       \n",
      "  7                  -1  1    656384  ultralytics.nn.modules.block.ADown           [512, 512]                    \n",
      "  8                  -1  1   2857472  ultralytics.nn.modules.block.RepNCSPELAN4    [512, 512, 512, 256, 1]       \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPELAN         [512, 512, 256]               \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1   3119616  ultralytics.nn.modules.block.RepNCSPELAN4    [1024, 512, 512, 256, 1]      \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1    912640  ultralytics.nn.modules.block.RepNCSPELAN4    [1024, 256, 256, 128, 1]      \n",
      " 16                  -1  1    164352  ultralytics.nn.modules.block.ADown           [256, 256]                    \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1   2988544  ultralytics.nn.modules.block.RepNCSPELAN4    [768, 512, 512, 256, 1]       \n",
      " 19                  -1  1    656384  ultralytics.nn.modules.block.ADown           [512, 512]                    \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1   3119616  ultralytics.nn.modules.block.RepNCSPELAN4    [1024, 512, 512, 256, 1]      \n",
      " 22        [15, 18, 21]  1   5585113  ultralytics.nn.modules.head.Detect           [3, [256, 512, 512]]          \n",
      "YOLOv9c summary: 358 layers, 25,531,545 parameters, 25,531,529 gradients, 103.7 GFLOPs\n",
      "\n",
      "Transferred 931/937 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt': 100% â”â”â”â”â”â”â”â”â”â”â”â” 5.4MB 4.0MB/s 1.3s1.3s<0.1s.8s9s\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1045.1Â±314.9 MB/s, size: 67.4 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/aup/data/YOLOv9_data/Aerial/SkyFusion-YOLOv9/train/labels... 2094 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2094/2094 723.0it/s 2.9s0.2s\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /home/aup/data/YOLOv9_data/Aerial/SkyFusion-YOLOv9/train/labels.cache\n",
      "WARNING âš ï¸ Box and segment counts should be equal, but got len(segments) = 34879, len(boxes) = 43575. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 680.7Â±215.2 MB/s, size: 68.9 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /home/aup/data/YOLOv9_data/Aerial/SkyFusion-YOLOv9/valid/labels... 449 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 449/449 663.9it/s 0.7s0.1s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /home/aup/data/YOLOv9_data/Aerial/SkyFusion-YOLOv9/valid/labels.cache\n",
      "WARNING âš ï¸ Box and segment counts should be equal, but got len(segments) = 6430, len(boxes) = 8387. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
      "Plotting labels to /home/aup/data/YOLOv9_data/runs/detect/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001429, momentum=0.9) with parameter groups 154 weight(decay=0.0), 161 weight(decay=0.0005), 160 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1m/home/aup/data/YOLOv9_data/runs/detect/train\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       1/10       4.7G      2.033       2.19      1.205          8        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 524/524 3.4it/s 2:33<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 57/57 7.4it/s 7.7s0.1s\n",
      "                   all        449       8387      0.362      0.344       0.33      0.186\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       2/10      4.77G      2.073      1.794      1.215          5        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 524/524 4.0it/s 2:12<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 57/57 8.2it/s 7.0s0.1s\n",
      "                   all        449       8387      0.958      0.283       0.35      0.189\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       3/10      4.84G      2.064      1.606      1.186         39        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 524/524 3.9it/s 2:14<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 57/57 8.2it/s 7.0s0.1s\n",
      "                   all        449       8387      0.523      0.344      0.369       0.21\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       4/10      4.92G      2.003      1.517      1.153         17        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 524/524 4.0it/s 2:11<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 57/57 8.2it/s 6.9s0.1s\n",
      "                   all        449       8387      0.466      0.414      0.378      0.213\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       5/10      4.99G      1.946      1.357      1.135          3        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 524/524 4.0it/s 2:12<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 57/57 7.9it/s 7.2s0.1s\n",
      "                   all        449       8387      0.495      0.346      0.391      0.222\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       6/10      5.07G       1.89      1.362      1.125          3        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 524/524 3.9it/s 2:13<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 57/57 8.2it/s 7.0s0.1s\n",
      "                   all        449       8387      0.533      0.479      0.451      0.247\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       7/10      5.14G      1.835      1.207       1.08         22        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 524/524 4.0it/s 2:11<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 57/57 8.1it/s 7.0s0.1s\n",
      "                   all        449       8387      0.547      0.493      0.458      0.246\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       8/10      5.21G      1.789      1.159      1.067          2        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 524/524 4.0it/s 2:12<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 57/57 8.2it/s 7.0s0.1s\n",
      "                   all        449       8387       0.52      0.489      0.455      0.257\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       9/10      5.29G      1.742      1.085      1.043          2        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 524/524 3.9it/s 2:13<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 57/57 7.1it/s 8.0s0.1s\n",
      "                   all        449       8387      0.573      0.503      0.468      0.262\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      10/10      5.36G      1.701      1.016      1.049          1        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 524/524 3.9it/s 2:15<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 57/57 7.9it/s 7.2s0.1s\n",
      "                   all        449       8387      0.573      0.531      0.496      0.279\n",
      "\n",
      "10 epochs completed in 0.398 hours.\n",
      "Optimizer stripped from /home/aup/data/YOLOv9_data/runs/detect/train/weights/last.pt, 51.6MB\n",
      "Optimizer stripped from /home/aup/data/YOLOv9_data/runs/detect/train/weights/best.pt, 51.6MB\n",
      "\n",
      "Validating /home/aup/data/YOLOv9_data/runs/detect/train/weights/best.pt...\n",
      "Ultralytics 8.3.205 ğŸš€ Python-3.10.18 torch-2.8.0+rocm6.4 CUDA:4 (AMD Radeon AI PRO R9700, 32624MiB)\n",
      "YOLOv9c summary (fused): 156 layers, 25,321,561 parameters, 0 gradients, 102.3 GFLOPs\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 57/57 8.1it/s 7.1s0.1s\n",
      "                   all        449       8387      0.574       0.53      0.496      0.279\n",
      "              Aircraft        149       1957      0.917      0.942      0.951      0.662\n",
      "                  ship        150        288      0.493      0.233      0.254     0.0901\n",
      "               vehicle        150       6142      0.311      0.415      0.284     0.0837\n",
      "Speed: 0.1ms preprocess, 11.4ms inference, 0.0ms loss, 1.3ms postprocess per image\n",
      "Results saved to \u001b[1m/home/aup/data/YOLOv9_data/runs/detect/train\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "results = model.train(\n",
    "    data=\"/home/aup/data/YOLOv9_data/Aerial/SkyFusion-YOLOv9/data.yaml\", epochs=10, imgsz=640, batch=4\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jZgJ0eO4jDAA"
   },
   "source": [
    "## 4. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PlMtb_H7PElB",
    "outputId": "9e4a2398-a7c1-4f1b-e817-32eb30e4d4ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/aup/data/YOLOv9_data/Aerial/SkyFusion-YOLOv9/test/images/3a1fe1cd4_png_jpg.rf.0b18c4bdcbdf18d62f557e6d2a1d01ca.jpg: 640x640 2 ships, 45.5ms\n",
      "Speed: 2.2ms preprocess, 45.5ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    }
   ],
   "source": [
    "results = model(\n",
    "    \"/home/aup/data/YOLOv9_data/Aerial/SkyFusion-YOLOv9/test/images/3a1fe1cd4_png_jpg.rf.0b18c4bdcbdf18d62f557e6d2a1d01ca.jpg\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /home/aup/data/YOLOv9_data/results/3a1fe1cd4_png_jpg.rf.0b18c4bdcbdf18d62f557e6d2a1d01ca_pred.jpg\n"
     ]
    }
   ],
   "source": [
    "import contextlib\n",
    "import pathlib\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "OUTPUT_DIR = \"/home/aup/data/YOLOv9_data/results\"\n",
    "for i, r in enumerate(results):\n",
    "    im_bgr = r.plot()\n",
    "    im_rgb = im_bgr[:, :, ::-1]\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(im_rgb)\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(f\"Prediction #{i}\")\n",
    "    plt.show()\n",
    "\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "    stem = f\"pred_{i}\"\n",
    "    with contextlib.suppress(Exception):\n",
    "        stem = pathlib.Path(r.path).stem\n",
    "    out_file = os.path.join(OUTPUT_DIR, f\"{stem}_pred.jpg\")\n",
    "    Image.fromarray(im_rgb).save(out_file)\n",
    "    print(\"Saved:\", out_file)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (dl_env)",
   "language": "python",
   "name": "dl_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
