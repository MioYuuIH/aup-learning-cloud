{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (C) 2025 Advanced Micro Devices, Inc. All rights reserved.\n",
    "Portions of this notebook consist of AI-generated content.\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "\n",
    "of this software and associated documentation files (the \"Software\"), to deal\n",
    "\n",
    "in the Software without restriction, including without limitation the rights\n",
    "\n",
    "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "\n",
    "copies of the Software, and to permit persons to whom the Software is\n",
    "\n",
    "furnished to do so, subject to the following conditions:\n",
    "\n",
    "\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all\n",
    "\n",
    "copies or substantial portions of the Software.\n",
    "\n",
    "\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "\n",
    "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "\n",
    "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "\n",
    "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "\n",
    "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "\n",
    "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "\n",
    "SOFTWARE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2: Deep Learning Basics - Foundation Concepts for LLM Development\n",
    "\n",
    "## Lab Overview\n",
    "\n",
    "This lab covers the fundamental concepts of deep learning that are essential for understanding Large Language Models and transformer architectures. We'll explore tensors, operations, gradients, and the mathematical foundations of neural networks.\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this lab, you will:\n",
    "- Master PyTorch tensor operations and computational graphs\n",
    "- Understand automatic differentiation and gradient computation\n",
    "- Learn the mathematical foundations of neural network training\n",
    "- Explore forward and backward propagation mechanics\n",
    "- Connect basic operations to transformer architectures\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AMD GPU environment initialized successfully\n",
      "Using device: cuda\n",
      "PyTorch version: 2.9.1+rocm7.10.0\n",
      "GPU: Radeon 8060S Graphics\n",
      "GPU Memory: 103.1 GB\n"
     ]
    }
   ],
   "source": [
    "# GPU Setup and Essential Imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Configure device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Tensor Fundamentals\n",
    "\n",
    "Tensors are the fundamental data structure in PyTorch and the building blocks of deep learning. Understanding tensors is crucial for working with neural networks and LLMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Tensor Creation and Properties ===\n",
      "Input tensor shape: torch.Size([10, 5]) | Device: cuda:0\n",
      "Weight tensor shape: torch.Size([5, 3]) | Device: cuda:0\n",
      "Weight requires gradients: True\n",
      "\n",
      "Input tensor (first 3 samples):\n",
      "tensor([[-0.2717,  0.1274,  0.2204, -1.1929,  0.7937],\n",
      "        [ 0.4641,  0.9397, -0.7696,  1.1303, -0.8973],\n",
      "        [-0.4169, -0.3124,  1.2784, -0.7402,  0.4081]], device='cuda:0')\n",
      "\n",
      "Weight tensor:\n",
      "tensor([[-0.0205,  0.9367,  0.1821],\n",
      "        [ 1.7163, -0.7320,  0.1128],\n",
      "        [-0.2981,  0.9027,  1.7040],\n",
      "        [-0.2520,  0.3341, -0.8225],\n",
      "        [-0.8891, -0.8946,  0.4043]], device='cuda:0', requires_grad=True)\n",
      "\n",
      "Key Insight: This setup simulates a neural network layer:\n",
      "   • Input: 10 samples with 5 features each\n",
      "   • Weights: Transform 5 input features to 3 output features\n",
      "   • This is the foundation of deep learning transformations!\n"
     ]
    }
   ],
   "source": [
    "# 2.1 Creating Tensors and Basic Operations\n",
    "\n",
    "print(\"=== Tensor Creation and Properties ===\")\n",
    "\n",
    "# Create tensors on GPU for optimal performance\n",
    "x = torch.randn(10, 5, device=device)  # Input tensor: 10 samples, 5 features each\n",
    "w = torch.randn(5, 3, requires_grad=True, device=device)  # Weight matrix: 5 inputs -> 3 outputs\n",
    "\n",
    "print(f\"Input tensor shape: {x.shape} | Device: {x.device}\")\n",
    "print(f\"Weight tensor shape: {w.shape} | Device: {w.device}\")\n",
    "print(f\"Weight requires gradients: {w.requires_grad}\")\n",
    "\n",
    "print(f\"\\nInput tensor (first 3 samples):\\n{x[:3]}\")\n",
    "print(f\"\\nWeight tensor:\\n{w}\")\n",
    "\n",
    "print(\"\\nKey Insight: This setup simulates a neural network layer:\")\n",
    "print(\" - Input: 10 samples with 5 features each\")\n",
    "print(\" - Weights: Transform 5 input features to 3 output features\")\n",
    "print(\" - This is the foundation of deep learning transformations!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Matrix Multiplication Methods ===\n",
      "Method 1 (@): torch.Size([10, 5]) @ torch.Size([5, 3]) Ã¢â€ â€™ torch.Size([10, 3])\n",
      "Result (first 3 samples):\n",
      "tensor([[-0.2464, -1.2575,  1.6425],\n",
      "        [ 2.3457,  0.2325, -2.4134],\n",
      "        [-1.0850,  0.3798,  2.8412]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "\n",
      "Method 2 (.matmul()): torch.Size([10, 3])\n",
      "Results identical: True\n",
      "\n",
      "Method 3 (torch.matmul()): torch.Size([10, 3])\n",
      "All methods identical: True\n",
      "\n",
      "Understanding the Transformation:\n",
      "   • Each of 10 samples (rows) gets transformed\n",
      "   • From 5 input features to 3 output features\n",
      "   • This is exactly what happens in neural network layers!\n",
      "   • Essential for: Linear layers, Attention mechanisms, LLM computations\n"
     ]
    }
   ],
   "source": [
    "# 2.2 Matrix Multiplication - The Heart of Neural Networks\n",
    "\n",
    "print(\"=== Matrix Multiplication Methods ===\")\n",
    "\n",
    "# Method 1: @ operator (most commonly used)\n",
    "y1 = x @ w  # Shape: (10, 5) @ (5, 3) -> (10, 3)\n",
    "print(f\"Method 1 (@): {x.shape} @ {w.shape} → {y1.shape}\")\n",
    "print(f\"Result (first 3 samples):\\n{y1[:3]}\")\n",
    "\n",
    "# Method 2: .matmul() method\n",
    "y2 = x.matmul(w)\n",
    "print(f\"\\nMethod 2 (.matmul()): {y2.shape}\")\n",
    "print(f\"Results identical: {torch.allclose(y1, y2)}\")\n",
    "\n",
    "# Method 3: torch.matmul() function\n",
    "y3 = torch.matmul(x, w)\n",
    "print(f\"\\nMethod 3 (torch.matmul()): {y3.shape}\")\n",
    "print(f\"All methods identical: {torch.allclose(y1, y3)}\")\n",
    "\n",
    "print(\"\\nUnderstanding the Transformation:\")\n",
    "print(\" - Each of 10 samples (rows) gets transformed\")\n",
    "print(\" - From 5 input features to 3 output features\")\n",
    "print(\" - This is exactly what happens in neural network layers!\")\n",
    "print(\" - Essential for: Linear layers, Attention mechanisms, LLM computations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PyTorch Linear Layer ===\n",
      "Linear layer weight shape: torch.Size([3, 5])\n",
      "Linear layer on device: cuda:0\n",
      "Linear layer bias: None\n",
      "\n",
      "Original weight matrix w:\n",
      "tensor([[-0.0205,  0.9367,  0.1821],\n",
      "        [ 1.7163, -0.7320,  0.1128],\n",
      "        [-0.2981,  0.9027,  1.7040],\n",
      "        [-0.2520,  0.3341, -0.8225],\n",
      "        [-0.8891, -0.8946,  0.4043]], device='cuda:0', requires_grad=True)\n",
      "Linear layer weight (w^T):\n",
      "Parameter containing:\n",
      "tensor([[-0.0205,  1.7163, -0.2981, -0.2520, -0.8891],\n",
      "        [ 0.9367, -0.7320,  0.9027,  0.3341, -0.8946],\n",
      "        [ 0.1821,  0.1128,  1.7040, -0.8225,  0.4043]], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "\n",
      "Linear layer output shape: torch.Size([10, 3])\n",
      "First 3 outputs:\n",
      "tensor([[-0.2464, -1.2575,  1.6425],\n",
      "        [ 2.3457,  0.2325, -2.4134],\n",
      "        [-1.0850,  0.3798,  2.8412]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "\n",
      "Manual matmul vs Linear layer: True\n",
      "\n",
      "PyTorch Linear Layers are:\n",
      "   • The building blocks of neural networks\n",
      "   • Used in: MLPs, Transformers, LLM projection layers\n",
      "   • Efficiently implement: y = xW^T + b\n",
      "   • Handle batching automatically\n"
     ]
    }
   ],
   "source": [
    "# 2.3 PyTorch Linear Layers - Neural Network Building Blocks\n",
    "\n",
    "print(\"=== PyTorch Linear Layer ===\")\n",
    "\n",
    "# Create linear layer and move to GPU\n",
    "linear = torch.nn.Linear(5, 3, bias=False).to(device)\n",
    "print(f\"Linear layer weight shape: {linear.weight.shape}\")\n",
    "print(f\"Linear layer on device: {linear.weight.device}\")\n",
    "print(f\"Linear layer bias: {linear.bias}\")\n",
    "\n",
    "# Set the weights to match our manual example\n",
    "linear.weight.data = w.T  # Note: Linear layers store weights transposed\n",
    "print(f\"\\nOriginal weight matrix w:\\n{w}\")\n",
    "print(f\"Linear layer weight (w^T):\\n{linear.weight}\")\n",
    "\n",
    "# Apply the linear transformation\n",
    "y_linear = linear(x)\n",
    "print(f\"\\nLinear layer output shape: {y_linear.shape}\")\n",
    "print(f\"First 3 outputs:\\n{y_linear[:3]}\")\n",
    "\n",
    "# Verify equivalence\n",
    "print(f\"\\nManual matmul vs Linear layer: {torch.allclose(y3, y_linear)}\")\n",
    "\n",
    "print(\"\\nPyTorch Linear Layers are:\")\n",
    "print(\" - The building blocks of neural networks\")\n",
    "print(\" - Used in: MLPs, Transformers, LLM projection layers\")\n",
    "print(\" - Efficiently implement: y = xW^T + b\")\n",
    "print(\" - Handle batching automatically\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Automatic Differentiation - The Magic of Backpropagation\n",
    "\n",
    "Automatic differentiation (autograd) is PyTorch's system for computing gradients automatically. This is essential for training neural networks through backpropagation.\n",
    "\n",
    "### 3.1 Gradient Computation Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Automatic Differentiation in Action ===\n",
      "Input shape: torch.Size([4, 5])\n",
      "Target shape: torch.Size([4, 3])\n",
      "Weight shape: torch.Size([5, 3])\n",
      "Bias shape: torch.Size([3])\n",
      "\n",
      "Forward pass:\n",
      "  Prediction shape: torch.Size([4, 3])\n",
      "  Loss value: 8.6003\n",
      "\n",
      "Gradients computed:\n",
      "  Weight gradient shape: torch.Size([5, 3])\n",
      "  Bias gradient shape: torch.Size([3])\n",
      "  Weight gradient norm: 4.5640\n",
      "  Bias gradient norm: 1.2576\n",
      "\n",
      "This is how neural networks learn:\n",
      "   1. Forward pass: Compute predictions\n",
      "   2. Loss computation: Measure prediction error\n",
      "   3. Backward pass: Compute gradients (Ã¢Ë†â€šLoss/Ã¢Ë†â€šparameters)\n",
      "   4. Parameter update: Adjust weights to reduce loss\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Automatic Differentiation in Action ===\")\n",
    "\n",
    "# Simple example: computing gradients of a loss function\n",
    "input_data = torch.randn(4, 5, device=device)\n",
    "target = torch.randn(4, 3, device=device)\n",
    "\n",
    "# Create learnable parameters\n",
    "weight = torch.randn(5, 3, requires_grad=True, device=device)\n",
    "bias = torch.randn(3, requires_grad=True, device=device)\n",
    "\n",
    "print(f\"Input shape: {input_data.shape}\")\n",
    "print(f\"Target shape: {target.shape}\")\n",
    "print(f\"Weight shape: {weight.shape}\")\n",
    "print(f\"Bias shape: {bias.shape}\")\n",
    "\n",
    "# Forward pass\n",
    "prediction = input_data @ weight + bias\n",
    "loss = torch.mean((prediction - target) ** 2)  # Mean Squared Error\n",
    "\n",
    "print(\"\\nForward pass:\")\n",
    "print(f\"  Prediction shape: {prediction.shape}\")\n",
    "print(f\"  Loss value: {loss.item():.4f}\")\n",
    "\n",
    "# Backward pass - compute gradients\n",
    "loss.backward()\n",
    "\n",
    "print(\"\\nGradients computed:\")\n",
    "print(f\"  Weight gradient shape: {weight.grad.shape}\")\n",
    "print(f\"  Bias gradient shape: {bias.grad.shape}\")\n",
    "print(f\"  Weight gradient norm: {weight.grad.norm().item():.4f}\")\n",
    "print(f\"  Bias gradient norm: {bias.grad.norm().item():.4f}\")\n",
    "\n",
    "print(\"\\nThis is how neural networks learn:\")\n",
    "print(\" - Forward pass: Compute predictions\")\n",
    "print(\" - Loss computation: Measure prediction error\")\n",
    "print(\" - Backward pass: Compute gradients (∂Loss/∂parameters)\")\n",
    "print(\" - Parameter update: Adjust weights to reduce loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Element-wise multiplication \n",
    "\n",
    "Element-wise multiplication applies the same operation independently to every position of two tensors with the **same shape** (or shapes that are **broadcastable**). In PyTorch you can use `*`, `.mul()`, or `torch.mul()`—they’re equivalent for element-wise multiply.\n",
    "\n",
    "**Definition (Hadamard product):** for tensors `A, B ∈ R^{m×n}`,\n",
    "`(A ⊙ B)_{ij} = A_{ij} × B_{ij}`.\n",
    "\n",
    "**Why it matters**\n",
    "- Used in gating (e.g., LSTM/GRU gates), attention masks, feature-wise scaling (LayerNorm/FiLM), and residual modulation.\n",
    "- Preserves shape, dtype, and device of the inputs; gradients flow element-by-element via autograd.\n",
    "- Squaring a tensor is just element-wise multiplication with itself: `z = w * w` (same as `w.pow(2)`). The gradient is `∂z/∂w = 2w`.\n",
    "\n",
    "**Element-wise vs. matrix multiply**\n",
    "- `*` multiplies element-by-element and returns the same shape as the inputs (after broadcasting).\n",
    "- `@` / `matmul` performs linear-algebraic matrix multiplication, e.g., `(m×k) @ (k×n) → (m×n)`.\n",
    "\n",
    "Below, we print `w`, compute `z = w * w`, and verify that a single entry squared (`w[i][j]**2`) equals the corresponding entry `z[i][j]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0205,  0.9367,  0.1821],\n",
      "        [ 1.7163, -0.7320,  0.1128],\n",
      "        [-0.2981,  0.9027,  1.7040],\n",
      "        [-0.2520,  0.3341, -0.8225],\n",
      "        [-0.8891, -0.8946,  0.4043]], device='cuda:0', requires_grad=True)\n",
      "tensor([[4.1980e-04, 8.7742e-01, 3.3146e-02],\n",
      "        [2.9456e+00, 5.3580e-01, 1.2734e-02],\n",
      "        [8.8845e-02, 8.1490e-01, 2.9037e+00],\n",
      "        [6.3523e-02, 1.1164e-01, 6.7657e-01],\n",
      "        [7.9047e-01, 8.0027e-01, 1.6345e-01]], device='cuda:0',\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor(0.6766, device='cuda:0', grad_fn=<PowBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# element wise multiplication\n",
    "\n",
    "print(w)\n",
    "\n",
    "z = w * w\n",
    "\n",
    "print(z)\n",
    "\n",
    "i = 3\n",
    "j = 2\n",
    "print(w[i][j] ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Tensor dtypes & devices (precision casting)\n",
    "\n",
    "Modern deep learning performance depends heavily on **dtype** (numeric precision) and **device** (CPU/GPU). PyTorch tensors carry both:\n",
    "- `dtype` (e.g., `torch.float32`, `torch.bfloat16`, `torch.float16`, `torch.int64`)\n",
    "- `device` (e.g., `cpu`, `cuda:0`, `mps:0`)\n",
    "\n",
    "**Why change dtype?**\n",
    "\n",
    "- **bfloat16 (bf16)** keeps the same exponent range as fp32 with fewer mantissa bits -> great for stable mixed-precision training on modern GPUs (including AMD ROCm), while saving memory and boosting throughput.\n",
    "- **float16 (fp16)** is faster but has a smaller exponent range -> may underflow/overflow more easily than bf16.\n",
    "- **float32 (fp32)** is the safe default for numerical stability, but uses more memory and compute.\n",
    "\n",
    "Below, we print a tensor's dtype and device, cast it to bfloat16, and confirm the new dtype.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0205,  0.9367,  0.1821],\n",
      "        [ 1.7163, -0.7320,  0.1128],\n",
      "        [-0.2981,  0.9027,  1.7040],\n",
      "        [-0.2520,  0.3341, -0.8225],\n",
      "        [-0.8891, -0.8946,  0.4043]], device='cuda:0', requires_grad=True) torch.float32 cuda:0\n",
      "torch.bfloat16\n"
     ]
    }
   ],
   "source": [
    "print(w, w.dtype, w.device)\n",
    "w1 = w.bfloat16()\n",
    "print(w1.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Neural Network Architectures\n",
    "\n",
    "Now let's explore how these fundamental operations combine to create neural networks, from simple multi-layer perceptrons to convolutional networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 40])\n"
     ]
    }
   ],
   "source": [
    "m1 = nn.Linear(20, 30)\n",
    "m2 = nn.Linear(30, 40)\n",
    "x = torch.randn(128, 20)\n",
    "y1 = m1(x)\n",
    "y2 = m2(y1)\n",
    "print(y2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 40])\n"
     ]
    }
   ],
   "source": [
    "x_large = torch.randn(128, 4096, 30, 20)\n",
    "y1_large = m1(x_large)\n",
    "y2_large = m2(y1_large)\n",
    "print(y2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1.]]]])\n",
      "tensor([[[[0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 1., 1., 1.],\n",
      "          [0., 0., 1., 1., 1.],\n",
      "          [0., 0., 1., 1., 1.]]]])\n",
      "tensor([[[[1., 2., 3.],\n",
      "          [2., 4., 6.],\n",
      "          [3., 6., 9.]]]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones((1, 1, 5, 5))\n",
    "print(x)\n",
    "x[:, :, :, 0] = 0\n",
    "x[:, :, :, 1] = 0\n",
    "x[:, :, 0, :] = 0\n",
    "x[:, :, 1, :] = 0\n",
    "print(x)\n",
    "conv_w = torch.ones((1, 1, 3, 3))\n",
    "\n",
    "y = nn.functional.conv2d(x, conv_w)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Complete Training Pipeline\n",
    "\n",
    "Now let's put everything together into a complete deep learning training pipeline using a classic CNN architecture on a real dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Loading FashionMNIST Dataset ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26.4M/26.4M [00:43<00:00, 601kB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Information:\n",
      "  Training samples: 60,000\n",
      "  Test samples: 10,000\n",
      "  Batch size: 64\n",
      "  Training batches: 938\n",
      "  Test batches: 157\n",
      "\n",
      "Batch Information:\n",
      "  Image batch shape: torch.Size([64, 1, 28, 28])\n",
      "  Label batch shape: torch.Size([64])\n",
      "  Image range: [0.000, 1.000]\n",
      "  Unique labels in batch: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "\n",
      "Class names: ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n"
     ]
    }
   ],
   "source": [
    "# 5.1 Dataset Loading and Preparation\n",
    "\n",
    "print(\"=== Loading FashionMNIST Dataset ===\")\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "# Load FashionMNIST dataset\n",
    "training_data = datasets.FashionMNIST(root=\"data\", train=True, download=True, transform=ToTensor())\n",
    "\n",
    "test_data = datasets.FashionMNIST(root=\"data\", train=False, download=True, transform=ToTensor())\n",
    "\n",
    "# Create data loaders for batched training\n",
    "batch_size = 64\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(\"Dataset Information:\")\n",
    "print(f\"  Training samples: {len(training_data):,}\")\n",
    "print(f\"  Test samples: {len(test_data):,}\")\n",
    "print(f\"  Batch size: {batch_size}\")\n",
    "print(f\"  Training batches: {len(train_dataloader):,}\")\n",
    "print(f\"  Test batches: {len(test_dataloader):,}\")\n",
    "\n",
    "# Check data format\n",
    "sample_batch = next(iter(train_dataloader))\n",
    "images, labels = sample_batch\n",
    "print(\"\\nBatch Information:\")\n",
    "print(f\"  Image batch shape: {images.shape}\")  # [batch_size, channels, height, width]\n",
    "print(f\"  Label batch shape: {labels.shape}\")  # [batch_size]\n",
    "print(f\"  Image range: [{images.min():.3f}, {images.max():.3f}]\")\n",
    "print(f\"  Unique labels in batch: {torch.unique(labels).tolist()}\")\n",
    "\n",
    "# Fashion-MNIST class names\n",
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]\n",
    "print(f\"\\nClass names: {class_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== LeNet-5 Architecture ===\n",
      "Model Architecture:\n",
      "LeNet(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=256, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n",
      "\n",
      "Model Statistics:\n",
      "  Total parameters: 44,426\n",
      "  Trainable parameters: 44,426\n",
      "  Model device: cuda:0\n",
      "\n",
      "Test forward pass:\n",
      "  Input shape: torch.Size([1, 1, 28, 28])\n",
      "  Output shape: torch.Size([1, 10])\n",
      "  Output probabilities: tensor([0.1148, 0.0896, 0.0889, 0.0970, 0.0922], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 5.2 LeNet Architecture - Classic Convolutional Neural Network\n",
    "# 5.2 LeNet Architecture - Classic Convolutional Neural Network\n",
    "\n",
    "print(\"=== LeNet-5 Architecture ===\")\n",
    "\n",
    "\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(1, 6, kernel_size=5)  # 28x28 -> 24x24\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)  # 12x12 -> 8x8\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)  # 16 channels * 4 * 4 = 256 -> 120\n",
    "        self.fc2 = nn.Linear(120, 84)  # 120 -> 84\n",
    "        self.fc3 = nn.Linear(84, num_classes)  # 84 -> 10 classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Conv layer 1 + ReLU + MaxPool\n",
    "        x = F.relu(self.conv1(x))  # [batch, 6, 24, 24]\n",
    "        x = F.max_pool2d(x, 2, 2)  # [batch, 6, 12, 12]\n",
    "\n",
    "        # Conv layer 2 + ReLU + MaxPool\n",
    "        x = F.relu(self.conv2(x))  # [batch, 16, 8, 8]\n",
    "        x = F.max_pool2d(x, 2, 2)  # [batch, 16, 4, 4]\n",
    "\n",
    "        # Flatten for fully connected layers\n",
    "        x = x.view(-1, 16 * 4 * 4)  # [batch, 256]\n",
    "\n",
    "        # Fully connected layers\n",
    "        x = F.relu(self.fc1(x))  # [batch, 120]\n",
    "        x = F.relu(self.fc2(x))  # [batch, 84]\n",
    "        x = self.fc3(x)  # [batch, 10]\n",
    "        return x\n",
    "\n",
    "\n",
    "# Create model and move to GPU\n",
    "model = LeNet(num_classes=10).to(device)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(\"Model Architecture:\")\n",
    "print(model)\n",
    "print(\"\\nModel Statistics:\")\n",
    "print(f\"  Total parameters: {total_params:,}\")\n",
    "print(f\"  Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"  Model device: {next(model.parameters()).device}\")\n",
    "\n",
    "# Test forward pass\n",
    "test_input = torch.randn(1, 1, 28, 28, device=device)\n",
    "test_output = model(test_input)\n",
    "print(\"\\nTest forward pass:\")\n",
    "print(f\"  Input shape: {test_input.shape}\")\n",
    "print(f\"  Output shape: {test_output.shape}\")\n",
    "print(f\"  Output probabilities: {F.softmax(test_output, dim=1)[0][:5]}\")  # First 5 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Training Setup ===\n",
      "Loss function: CrossEntropyLoss()\n",
      "Optimizer: SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    differentiable: False\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "\n",
      "=== Training Started ===\n",
      "\n",
      "Epoch 1/5\n",
      "--------------------------------------------------\n",
      "  Batch   0/938 | Loss: 0.3842 | Acc:  89.1%\n",
      "  Batch 200/938 | Loss: 0.5591 | Acc:  80.3%\n",
      "  Batch 400/938 | Loss: 0.5601 | Acc:  80.1%\n",
      "  Batch 600/938 | Loss: 0.5557 | Acc:  80.3%\n",
      "  Batch 800/938 | Loss: 0.5397 | Acc:  80.5%\n",
      "\n",
      "Epoch 1 Summary:\n",
      "  Train Loss: 0.5240 | Train Acc: 80.73%\n",
      "  Test Loss:  0.5266 | Test Acc:  81.10%\n",
      "\n",
      "Epoch 2/5\n",
      "--------------------------------------------------\n",
      "  Batch   0/938 | Loss: 0.4744 | Acc:  89.1%\n",
      "  Batch 200/938 | Loss: 0.4347 | Acc:  81.5%\n",
      "  Batch 400/938 | Loss: 0.3430 | Acc:  81.4%\n",
      "  Batch 600/938 | Loss: 0.3447 | Acc:  81.6%\n",
      "  Batch 800/938 | Loss: 0.4633 | Acc:  81.8%\n",
      "\n",
      "Epoch 2 Summary:\n",
      "  Train Loss: 0.4968 | Train Acc: 81.79%\n",
      "  Test Loss:  0.5362 | Test Acc:  80.78%\n",
      "\n",
      "Epoch 3/5\n",
      "--------------------------------------------------\n",
      "  Batch   0/938 | Loss: 0.5141 | Acc:  81.2%\n",
      "  Batch 200/938 | Loss: 0.5480 | Acc:  82.1%\n",
      "  Batch 400/938 | Loss: 0.3878 | Acc:  82.4%\n",
      "  Batch 600/938 | Loss: 0.7159 | Acc:  82.7%\n",
      "  Batch 800/938 | Loss: 0.4469 | Acc:  82.8%\n",
      "\n",
      "Epoch 3 Summary:\n",
      "  Train Loss: 0.4704 | Train Acc: 82.94%\n",
      "  Test Loss:  0.4882 | Test Acc:  82.15%\n",
      "\n",
      "Epoch 4/5\n",
      "--------------------------------------------------\n",
      "  Batch   0/938 | Loss: 0.5958 | Acc:  81.2%\n",
      "  Batch 200/938 | Loss: 0.5340 | Acc:  83.3%\n",
      "  Batch 400/938 | Loss: 0.3174 | Acc:  83.3%\n",
      "  Batch 600/938 | Loss: 0.3358 | Acc:  83.4%\n",
      "  Batch 800/938 | Loss: 0.5099 | Acc:  83.7%\n",
      "\n",
      "Epoch 4 Summary:\n",
      "  Train Loss: 0.4512 | Train Acc: 83.66%\n",
      "  Test Loss:  0.4554 | Test Acc:  83.46%\n",
      "\n",
      "Epoch 5/5\n",
      "--------------------------------------------------\n",
      "  Batch   0/938 | Loss: 0.3252 | Acc:  89.1%\n",
      "  Batch 200/938 | Loss: 0.3413 | Acc:  84.3%\n",
      "  Batch 400/938 | Loss: 0.3779 | Acc:  84.6%\n",
      "  Batch 600/938 | Loss: 0.3609 | Acc:  84.6%\n",
      "  Batch 800/938 | Loss: 0.8230 | Acc:  84.4%\n",
      "\n",
      "Epoch 5 Summary:\n",
      "  Train Loss: 0.4311 | Train Acc: 84.50%\n",
      "  Test Loss:  0.4385 | Test Acc:  84.21%\n",
      "\n",
      "Training Complete!\n",
      "Final Test Accuracy: 84.21%\n",
      "\n",
      "Key Learning Points:\n",
      "   • Forward pass: Data flows through network layers\n",
      "   • Loss computation: Measures prediction errors\n",
      "   • Backward pass: Computes gradients via chain rule\n",
      "   • Parameter update: Moves in direction of negative gradient\n",
      "   • This is the foundation of ALL deep learning!\n",
      "   • Same principles apply to LLMs, just different architectures\n"
     ]
    }
   ],
   "source": [
    "# 5.3 Complete Training Pipeline\n",
    "\n",
    "print(\"=== Training Setup ===\")\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3, momentum=0.9)\n",
    "\n",
    "print(f\"Loss function: {criterion}\")\n",
    "print(f\"Optimizer: {optimizer}\")\n",
    "\n",
    "\n",
    "def train_epoch(dataloader, model, loss_fn, optimizer, device):\n",
    "    \"\"\"Train the model for one epoch\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for batch_idx, (X, y) in enumerate(dataloader):\n",
    "        # Move data to GPU\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()  # Clear gradients\n",
    "        loss.backward()  # Compute gradients\n",
    "        optimizer.step()  # Update parameters\n",
    "\n",
    "        # Statistics\n",
    "        total_loss += loss.item()\n",
    "        _, predicted = pred.max(1)\n",
    "        total += y.size(0)\n",
    "        correct += predicted.eq(y).sum().item()\n",
    "\n",
    "        # Print progress\n",
    "        if batch_idx % 200 == 0:\n",
    "            print(\n",
    "                f\"  Batch {batch_idx:>3d}/{len(dataloader):>3d} | \"\n",
    "                f\"Loss: {loss.item():>6.4f} | \"\n",
    "                f\"Acc: {100.0 * correct / total:>5.1f}%\"\n",
    "            )\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    accuracy = 100.0 * correct / total\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "\n",
    "def test_epoch(dataloader, model, loss_fn, device):\n",
    "    \"\"\"Evaluate the model\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            loss = loss_fn(pred, y)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            _, predicted = pred.max(1)\n",
    "            total += y.size(0)\n",
    "            correct += predicted.eq(y).sum().item()\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    accuracy = 100.0 * correct / total\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "\n",
    "# Training loop\n",
    "print(\"\\n=== Training Started ===\")\n",
    "epochs = 5  # Reduced for demo\n",
    "train_losses, train_accs = [], []\n",
    "test_losses, test_accs = [], []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    # Train\n",
    "    train_loss, train_acc = train_epoch(train_dataloader, model, criterion, optimizer, device)\n",
    "    train_losses.append(train_loss)\n",
    "    train_accs.append(train_acc)\n",
    "\n",
    "    # Test\n",
    "    test_loss, test_acc = test_epoch(test_dataloader, model, criterion, device)\n",
    "    test_losses.append(test_loss)\n",
    "    test_accs.append(test_acc)\n",
    "\n",
    "    print(f\"\\nEpoch {epoch + 1} Summary:\")\n",
    "    print(f\"  Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%\")\n",
    "    print(f\"  Test Loss:  {test_loss:.4f} | Test Acc:  {test_acc:.2f}%\")\n",
    "\n",
    "print(\"\\nTraining Complete!\")\n",
    "print(f\"Final Test Accuracy: {test_accs[-1]:.2f}%\")\n",
    "\n",
    "print(\"\\nKey Learning Points:\")\n",
    "print(\" - Forward pass: Data flows through network layers\")\n",
    "print(\" - Loss computation: Measures prediction errors\")\n",
    "print(\" - Backward pass: Computes gradients via chain rule\")\n",
    "print(\" - Parameter update: Moves in direction of negative gradient\")\n",
    "print(\" - This is the foundation of ALL deep learning!\")\n",
    "print(\" - Same principles apply to LLMs, just different architectures\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Summary\n",
    "\n",
    "### Technical Concepts Learned\n",
    "- **Tensor Fundamentals**: Creating tensors, understanding shapes, devices, and basic properties in PyTorch\n",
    "- **Matrix Multiplication**: Core operation for neural networks using torch.matmul, and nn.Linear layers\n",
    "- **Automatic Differentiation**: Introduction to requires_grad, backward(), and gradient computation\n",
    "- **Element-wise Operations**: Hadamard product and basic tensor arithmetic\n",
    "- **Data Types**: Understanding float32, float16, bfloat16 and their memory implications\n",
    "- **Basic Neural Networks**: Building simple MLPs and LeNet CNN architecture\n",
    "- **Training Fundamentals**: Forward pass, loss computation, backward pass, and parameter updates\n",
    "\n",
    "### Experiment Further\n",
    "- Create tensors with different shapes and verify matrix multiplication dimensions\n",
    "- Compute gradients manually and compare with autograd results\n",
    "- Modify the MLP hidden layer sizes and observe effects on accuracy\n",
    "- Try different activation functions (ReLU, Tanh, Sigmoid) in the networks\n",
    "- Change the number of training epochs and observe convergence\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
