{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fb27b941602401d91542211134fc71a",
   "metadata": {},
   "source": [
    "Copyright (C) 2025 Advanced Micro Devices, Inc. All rights reserved.\n",
    "Portions of this notebook consist of AI-generated content.\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "\n",
    "of this software and associated documentation files (the \"Software\"), to deal\n",
    "\n",
    "in the Software without restriction, including without limitation the rights\n",
    "\n",
    "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "\n",
    "copies of the Software, and to permit persons to whom the Software is\n",
    "\n",
    "furnished to do so, subject to the following conditions:\n",
    "\n",
    "\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all\n",
    "\n",
    "copies or substantial portions of the Software.\n",
    "\n",
    "\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "\n",
    "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "\n",
    "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "\n",
    "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "\n",
    "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "\n",
    "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "\n",
    "SOFTWARE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "y_NnKd-wRj_Y",
   "metadata": {
    "id": "y_NnKd-wRj_Y"
   },
   "source": [
    "# DL10 Sequence-to-Sequence (Seq2Seq)\n",
    "\n",
    "### Lab Description\n",
    "\n",
    "This laboratory exercise introduces the **Sequence-to-Sequence (Seq2Seq)** architecture using Recurrent Neural Networks (RNNs) with Long Short-Term Memory (LSTM), a widely adopted technique in machine learning for sequence-based tasks. Seq2Seq is especially useful for applications such as machine translation, text summarization, and conversational modeling.\n",
    "\n",
    "In this hands-on lab, students will construct a basic `English-to-Chinese` translation model using a small dataset of sentence pairs. The model will consist of an LSTM-based encoder and decoder. Through the training and inference process, students will gain practical understanding of how Seq2Seq models operate.\n",
    "\n",
    "### What you can expect to learn\n",
    "\n",
    "- Structural Understanding: Understand the basic architecture of a Seq2Seq model, including the roles of the encoder and decoder.\n",
    "- Model Implementation: Learn how to implement Seq2Seq using LSTM layers in PyTorch.\n",
    "- Training Technique: Explore the use of teacher forcing to improve training efficiency and convergence.\n",
    "- Inference Practice: Gain experience in translating English sentences into Chinese using a trained Seq2Seq model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Cl6GCJrBR6gF",
   "metadata": {
    "id": "Cl6GCJrBR6gF"
   },
   "source": [
    "### Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc8a9c6-ae40-4f36-8533-e5bddefe759f",
   "metadata": {
    "executionInfo": {
     "elapsed": 4223,
     "status": "ok",
     "timestamp": 1754806074189,
     "user": {
      "displayName": "LIAO FLORA",
      "userId": "18011015488649422122"
     },
     "user_tz": -480
    },
    "id": "fdc8a9c6-ae40-4f36-8533-e5bddefe759f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "print(\"GPU Name:\", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6OW1AlZUR-Pf",
   "metadata": {
    "id": "6OW1AlZUR-Pf"
   },
   "source": [
    "### Required Dataset\n",
    "We will use a small English-Chinese phrase dataset in the format:\n",
    "\n",
    "```\n",
    "Hello\t你好\n",
    "How are you?\t你好嗎？\n",
    "```\n",
    "\n",
    "If you don’t have the dataset yet, you can create a small file called `eng-chn.txt` manually or download it from a trusted source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dQ_3MbHfSNg_",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 34,
     "status": "ok",
     "timestamp": 1754807478383,
     "user": {
      "displayName": "LIAO FLORA",
      "userId": "18011015488649422122"
     },
     "user_tz": -480
    },
    "id": "dQ_3MbHfSNg_",
    "outputId": "9ba2f418-b832-4fef-ee7d-92203b9b8740"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] loaded 747 clean pairs from /home/aup/data/eng-chn.txt\n",
      "['i am from please taipei', '我来自太平']\n"
     ]
    }
   ],
   "source": [
    "import hashlib\n",
    "\n",
    "\n",
    "def _norm_en(s: str) -> str:\n",
    "    s = s.strip().lower()\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-z0-9’'.,!? \\-]+\", \" \", s)\n",
    "    s = re.sub(r\"\\s+\", \" \", s)\n",
    "    return s.strip()\n",
    "\n",
    "\n",
    "def _norm_zh(s: str) -> str:\n",
    "    s = s.strip()\n",
    "    s = re.sub(r\"[^\\u4e00-\\u9fffA-Za-z0-9，。！？、\\.!?（）()：:；;“”\\\"\\'《》【】\\[\\]\\s\\-]+\", \" \", s)\n",
    "    s = re.sub(r\"\\s+\", \" \", s)\n",
    "    return s.strip()\n",
    "\n",
    "\n",
    "def _valid_pair(en: str, zh: str, max_en_tokens=20, max_zh_chars=60, ratio_max=8.0) -> bool:\n",
    "    if not en or not zh:\n",
    "        return False\n",
    "    en_len = len(en.split())\n",
    "    zh_len = len(zh)\n",
    "    if en_len == 0 or en_len > max_en_tokens:\n",
    "        return False\n",
    "    if zh_len > max_zh_chars:\n",
    "        return False\n",
    "    return not zh_len / max(1, en_len) > ratio_max\n",
    "\n",
    "\n",
    "def read_data(filepath: str, num_sentences: int | None = None, char_level_zh: bool = False, deduplicate: bool = True):\n",
    "    pairs, seen = [], set()\n",
    "    with open(filepath, encoding=\"utf-8\") as f:\n",
    "        for i, line in enumerate(f, 1):\n",
    "            if num_sentences and i > num_sentences:\n",
    "                break\n",
    "            if \"\\t\" not in line:\n",
    "                continue\n",
    "            en, zh = line.rstrip(\"\\n\").split(\"\\t\", 1)\n",
    "            en, zh = _norm_en(en), _norm_zh(zh)\n",
    "            if not _valid_pair(en, zh):\n",
    "                continue\n",
    "            if char_level_zh:\n",
    "                zh = \" \".join(list(zh))\n",
    "            if deduplicate:\n",
    "                key = hashlib.md5(f\"{en}\\t{zh}\".encode()).hexdigest()\n",
    "                if key in seen:\n",
    "                    continue\n",
    "                seen.add(key)\n",
    "            pairs.append([en, zh])\n",
    "    print(f\"[info] loaded {len(pairs)} clean pairs from {filepath}\")\n",
    "    return pairs\n",
    "\n",
    "\n",
    "dataset_path = os.path.expanduser(\"./eng-chn.txt\")\n",
    "pairs = read_data(dataset_path, num_sentences=1000, char_level_zh=False, deduplicate=True)\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2sX2TAB5Sf0H",
   "metadata": {
    "id": "2sX2TAB5Sf0H"
   },
   "source": [
    "### Define Encoder and Decoder Models\n",
    "\n",
    "The Seq2Seq model is composed of two main components: an **Encoder** and a **Decoder**, both implemented using LSTM layers.\n",
    "\n",
    "- **EncoderRNN**: Takes in an input sequence (e.g., an English sentence), embeds each token, and passes the sequence through an LSTM. The final hidden and cell states summarize the input and are passed to the decoder.\n",
    "\n",
    "- **DecoderRNN**: Starts from a special start-of-sequence token (`SOS_token`) and uses the encoded state to begin generating an output sequence (e.g., a Chinese sentence), one word at a time. It produces a probability distribution over the output vocabulary at each step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "TqpSUK8gSgok",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1754807891937,
     "user": {
      "displayName": "LIAO FLORA",
      "userId": "18011015488649422122"
     },
     "user_tz": -480
    },
    "id": "TqpSUK8gSgok"
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)  # (1, batch=1, hidden_size)\n",
    "        output, hidden = self.lstm(embedded, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        h0 = torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "        c0 = torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "        return (h0, c0)\n",
    "\n",
    "\n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)  # (1, batch=1, hidden_size)\n",
    "        output, hidden = self.lstm(embedded, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        h0 = torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "        c0 = torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "        return (h0, c0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ZDfHjQNKSi3a",
   "metadata": {
    "id": "ZDfHjQNKSi3a"
   },
   "source": [
    "### Build Vocabulary and Index Mapping\n",
    "\n",
    "To train a Seq2Seq model, both the input and output languages must be converted into numerical representations. This is done by building a vocabulary and assigning a unique index to each word.\n",
    "\n",
    "- We define two special tokens: `SOS_token` for start-of-sequence and `EOS_token` for end-of-sequence.\n",
    "- The `Lang` class is used to:\n",
    "  - Store mappings between words and indices.\n",
    "  - Count word frequencies.\n",
    "  - Maintain both `word2index` and `index2word` dictionaries.\n",
    "- For each sentence pair in the dataset, we populate the English (`input_lang`) and Chinese (`output_lang`) vocabularies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "JJ5qtHz4Sk73",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1754807895785,
     "user": {
      "displayName": "LIAO FLORA",
      "userId": "18011015488649422122"
     },
     "user_tz": -480
    },
    "id": "JJ5qtHz4Sk73"
   },
   "outputs": [],
   "source": [
    "# Special tokens\n",
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(\" \"):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "\n",
    "\n",
    "input_lang = Lang(\"eng\")\n",
    "output_lang = Lang(\"chn\")\n",
    "\n",
    "for pair in pairs:\n",
    "    input_lang.addSentence(pair[0])\n",
    "    output_lang.addSentence(pair[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jl5bdkO8SnMg",
   "metadata": {
    "id": "jl5bdkO8SnMg"
   },
   "source": [
    "### Tensor Preparation\n",
    "\n",
    "Neural networks require input in the form of tensors. To convert natural language into tensors, we use the following helper functions:\n",
    "\n",
    "- `indexesFromSentence(lang, sentence)`: Converts a sentence into a list of word indices based on the language's vocabulary.\n",
    "- `tensorFromSentence(lang, sentence)`: Converts the list of indices into a PyTorch tensor and appends the `EOS_token` to indicate the end of the sequence.\n",
    "- `tensorsFromPair(pair)`: Applies the conversion to both the input and output sentences in a sentence pair, returning the input and target tensors.\n",
    "\n",
    "These functions prepare our sentence pairs for model training by converting them into a numerical format that the encoder and decoder can process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1RXXS8WnSpe4",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1754807897937,
     "user": {
      "displayName": "LIAO FLORA",
      "userId": "18011015488649422122"
     },
     "user_tz": -480
    },
    "id": "1RXXS8WnSpe4"
   },
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(\" \") if word in lang.word2index]\n",
    "\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long).view(-1, 1)\n",
    "\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return input_tensor, target_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "T-mZf_FnSriq",
   "metadata": {
    "id": "T-mZf_FnSriq"
   },
   "source": [
    "### Training Function\n",
    "\n",
    "This function performs a single training step for the Seq2Seq model using a pair of input and target tensors. It follows the standard encoder-decoder training loop.\n",
    "\n",
    "The encoder processes the input sequence and produces a hidden state that summarizes the input. The decoder then generates the target sequence one token at a time. During training, we use **teacher forcing**, where the correct target token is fed into the decoder as the next input with a certain probability (defined by `teacher_forcing_ratio`). This accelerates convergence and improves early-stage learning.\n",
    "\n",
    "The function calculates the total loss using negative log-likelihood and updates both the encoder and decoder weights through backpropagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38c07bbc-6c8e-4f76-ae11-8176e7bebf7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import shutil\n",
    "import subprocess\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "def _to_mb(x):\n",
    "    return None if x is None else round(x / (1024**2), 2)\n",
    "\n",
    "\n",
    "def _which_rocm_smi():\n",
    "    p = shutil.which(\"rocm-smi\")\n",
    "    if p:\n",
    "        return p\n",
    "    return \"/opt/rocm/bin/rocm-smi\" if os.path.exists(\"/opt/rocm/bin/rocm-smi\") else None\n",
    "\n",
    "\n",
    "_ROCM_SMI = _which_rocm_smi()\n",
    "\n",
    "\n",
    "def rocm_query_util_and_vram():\n",
    "    \"\"\"Return {'util_percent': float|None, 'used_mib': float|None} from rocm-smi.\"\"\"\n",
    "    if not _ROCM_SMI:\n",
    "        return {\"util_percent\": None, \"used_mib\": None}\n",
    "    # Try JSON first\n",
    "    try:\n",
    "        out = subprocess.check_output([_ROCM_SMI, \"--json\"], text=True, stderr=subprocess.STDOUT, timeout=3)\n",
    "        data = json.loads(out)\n",
    "        card = data.get(\"card0\") or data.get(\"card_0\") or next(iter(data.values()))\n",
    "        util = None\n",
    "        used = None\n",
    "        if isinstance(card, dict):\n",
    "            util = card.get(\"GPU use (%)\")\n",
    "            if isinstance(util, str):\n",
    "                util = float(re.sub(r\"[^\\d.]+\", \"\", util))\n",
    "            vram = card.get(\"VRAM\") or card.get(\"vram\") or {}\n",
    "            used = vram.get(\"memory used (MiB)\") or vram.get(\"used (MiB)\")\n",
    "            if isinstance(used, str):\n",
    "                used = float(re.sub(r\"[^\\d.]+\", \"\", used))\n",
    "        return {\n",
    "            \"util_percent\": (None if util is None else float(util)),\n",
    "            \"used_mib\": (None if used is None else float(used)),\n",
    "        }\n",
    "    except Exception:\n",
    "        pass\n",
    "    # Fallback: human-readable\n",
    "    try:\n",
    "        out = subprocess.check_output(\n",
    "            [_ROCM_SMI, \"--showuse\", \"--showmemuse\"], text=True, stderr=subprocess.STDOUT, timeout=3\n",
    "        )\n",
    "        m_util = re.search(r\"GPU\\s*use.*?:\\s*([0-9]+)\", out, re.I)\n",
    "        m_used = re.search(r\"(VRAM.*Used|memory\\s*used).*?\\(MiB\\)\\s*:\\s*([0-9]+)\", out, re.I)\n",
    "        util = float(m_util.group(1)) if m_util else None\n",
    "        used = float(m_used.group(2)) if m_used else None\n",
    "        return {\"util_percent\": util, \"used_mib\": used}\n",
    "    except Exception:\n",
    "        return {\"util_percent\": None, \"used_mib\": None}\n",
    "\n",
    "\n",
    "def get_vram_stats(device_id: int = 0):\n",
    "    \"\"\"Return current/reserved/peak VRAM usage in MB.\"\"\"\n",
    "    if not torch.cuda.is_available():\n",
    "        return {\"alloc\": None, \"resv\": None, \"peak\": None}\n",
    "\n",
    "    alloc = torch.cuda.memory_allocated(device_id) / 1024**2\n",
    "    resv = torch.cuda.memory_reserved(device_id) / 1024**2\n",
    "    peak = torch.cuda.max_memory_allocated(device_id) / 1024**2\n",
    "    return {\"alloc\": round(alloc, 2), \"resv\": round(resv, 2), \"peak\": round(peak, 2)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "UXDYIpxjStup",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1754807907185,
     "user": {
      "displayName": "LIAO FLORA",
      "userId": "18011015488649422122"
     },
     "user_tz": -480
    },
    "id": "UXDYIpxjStup"
   },
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    # --- Encoder ---\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(input_tensor[ei].to(device), encoder_hidden)\n",
    "\n",
    "    # --- Decoder init ---\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = random.random() < teacher_forcing_ratio\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # --- Teacher forcing ---\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "            loss += criterion(decoder_output, target_tensor[di].to(device))\n",
    "            decoder_input = target_tensor[di].unsqueeze(0).to(device)\n",
    "    else:\n",
    "        # --- Without teacher forcing ---\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.detach().view(1, 1).to(device)\n",
    "            loss += criterion(decoder_output, target_tensor[di].to(device))\n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "\n",
    "    # --- Backprop ---\n",
    "    loss.backward()\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42KPWRwvSvpR",
   "metadata": {
    "id": "42KPWRwvSvpR"
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "AjHvuj26SyZV",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 453103,
     "status": "ok",
     "timestamp": 1754809389820,
     "user": {
      "displayName": "LIAO FLORA",
      "userId": "18011015488649422122"
     },
     "user_tz": -480
    },
    "id": "AjHvuj26SyZV",
    "outputId": "dbb67f50-9ae1-4b42-c0df-dc45e0375ba7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50] | Avg Loss: 3.8254 | Time: 4.33s | VRAM alloc/resv/peak(MB)=45.94/216.0/169.6 | GPU util%=100.0 | rsmi_used(MiB)=None\n",
      "Epoch [2/50] | Avg Loss: 3.9335 | Time: 4.74s | VRAM alloc/resv/peak(MB)=45.94/216.0/169.6 | GPU util%=100.0 | rsmi_used(MiB)=None\n",
      "Epoch [3/50] | Avg Loss: 3.5622 | Time: 4.78s | VRAM alloc/resv/peak(MB)=45.94/216.0/169.6 | GPU util%=100.0 | rsmi_used(MiB)=None\n",
      "Epoch [4/50] | Avg Loss: 3.1831 | Time: 4.45s | VRAM alloc/resv/peak(MB)=45.94/216.0/169.6 | GPU util%=100.0 | rsmi_used(MiB)=None\n",
      "Epoch [5/50] | Avg Loss: 2.8420 | Time: 4.81s | VRAM alloc/resv/peak(MB)=45.94/216.0/169.6 | GPU util%=100.0 | rsmi_used(MiB)=None\n",
      "Epoch [6/50] | Avg Loss: 2.4578 | Time: 4.86s | VRAM alloc/resv/peak(MB)=45.94/216.0/169.6 | GPU util%=100.0 | rsmi_used(MiB)=None\n",
      "Epoch [7/50] | Avg Loss: 2.0641 | Time: 4.90s | VRAM alloc/resv/peak(MB)=45.94/216.0/169.6 | GPU util%=100.0 | rsmi_used(MiB)=None\n",
      "Epoch [8/50] | Avg Loss: 1.6496 | Time: 4.54s | VRAM alloc/resv/peak(MB)=45.94/216.0/169.6 | GPU util%=100.0 | rsmi_used(MiB)=None\n",
      "Epoch [9/50] | Avg Loss: 1.2511 | Time: 4.95s | VRAM alloc/resv/peak(MB)=45.94/216.0/169.6 | GPU util%=100.0 | rsmi_used(MiB)=None\n",
      "Epoch [10/50] | Avg Loss: 0.8929 | Time: 4.93s | VRAM alloc/resv/peak(MB)=45.94/216.0/169.6 | GPU util%=100.0 | rsmi_used(MiB)=None\n",
      "Epoch [11/50] | Avg Loss: 0.5983 | Time: 4.94s | VRAM alloc/resv/peak(MB)=45.94/216.0/169.6 | GPU util%=100.0 | rsmi_used(MiB)=None\n",
      "Epoch [12/50] | Avg Loss: 0.4100 | Time: 4.88s | VRAM alloc/resv/peak(MB)=45.94/216.0/169.6 | GPU util%=100.0 | rsmi_used(MiB)=None\n",
      "Epoch [13/50] | Avg Loss: 0.2624 | Time: 4.94s | VRAM alloc/resv/peak(MB)=45.94/216.0/169.6 | GPU util%=100.0 | rsmi_used(MiB)=None\n",
      "Epoch [14/50] | Avg Loss: 0.1811 | Time: 4.61s | VRAM alloc/resv/peak(MB)=45.94/216.0/169.6 | GPU util%=100.0 | rsmi_used(MiB)=None\n",
      "Epoch [15/50] | Avg Loss: 0.1265 | Time: 4.81s | VRAM alloc/resv/peak(MB)=45.94/216.0/169.6 | GPU util%=100.0 | rsmi_used(MiB)=None\n",
      "Epoch [16/50] | Avg Loss: 0.0963 | Time: 4.95s | VRAM alloc/resv/peak(MB)=45.94/216.0/169.6 | GPU util%=100.0 | rsmi_used(MiB)=None\n",
      "Epoch [17/50] | Avg Loss: 0.0784 | Time: 4.93s | VRAM alloc/resv/peak(MB)=45.94/216.0/169.6 | GPU util%=100.0 | rsmi_used(MiB)=None\n",
      "Epoch [18/50] | Avg Loss: 0.0593 | Time: 4.69s | VRAM alloc/resv/peak(MB)=45.94/216.0/169.6 | GPU util%=100.0 | rsmi_used(MiB)=None\n",
      "Epoch [19/50] | Avg Loss: 0.0546 | Time: 4.95s | VRAM alloc/resv/peak(MB)=45.94/216.0/169.6 | GPU util%=100.0 | rsmi_used(MiB)=None\n",
      "Epoch [20/50] | Avg Loss: 0.0446 | Time: 4.69s | VRAM alloc/resv/peak(MB)=45.94/216.0/169.6 | GPU util%=100.0 | rsmi_used(MiB)=None\n",
      "Epoch [21/50] | Avg Loss: 0.0438 | Time: 4.97s | VRAM alloc/resv/peak(MB)=45.94/216.0/169.6 | GPU util%=100.0 | rsmi_used(MiB)=None\n",
      "Epoch [22/50] | Avg Loss: 0.0366 | Time: 4.98s | VRAM alloc/resv/peak(MB)=45.94/216.0/169.6 | GPU util%=100.0 | rsmi_used(MiB)=None\n",
      "Epoch [23/50] | Avg Loss: 0.0386 | Time: 4.73s | VRAM alloc/resv/peak(MB)=45.94/216.0/169.6 | GPU util%=100.0 | rsmi_used(MiB)=None\n",
      "Epoch [24/50] | Avg Loss: 0.0387 | Time: 5.02s | VRAM alloc/resv/peak(MB)=45.94/216.0/169.6 | GPU util%=100.0 | rsmi_used(MiB)=None\n",
      "Epoch [25/50] | Avg Loss: 0.0368 | Time: 4.99s | VRAM alloc/resv/peak(MB)=45.94/216.0/169.6 | GPU util%=100.0 | rsmi_used(MiB)=None\n",
      "Epoch [26/50] | Avg Loss: 0.0337 | Time: 5.00s | VRAM alloc/resv/peak(MB)=45.94/216.0/169.6 | GPU util%=100.0 | rsmi_used(MiB)=None\n",
      "Epoch [27/50] | Avg Loss: 0.0308 | Time: 4.70s | VRAM alloc/resv/peak(MB)=45.94/216.0/169.6 | GPU util%=100.0 | rsmi_used(MiB)=None\n",
      "Epoch [28/50] | Avg Loss: 0.0340 | Time: 4.89s | VRAM alloc/resv/peak(MB)=45.94/216.0/169.6 | GPU util%=100.0 | rsmi_used(MiB)=None\n",
      "Epoch [29/50] | Avg Loss: 0.0367 | Time: 4.71s | VRAM alloc/resv/peak(MB)=45.94/216.0/169.6 | GPU util%=100.0 | rsmi_used(MiB)=None\n",
      "Epoch [30/50] | Avg Loss: 0.0285 | Time: 5.00s | VRAM alloc/resv/peak(MB)=45.94/216.0/169.6 | GPU util%=100.0 | rsmi_used(MiB)=None\n",
      "Epoch [31/50] | Avg Loss: 0.0272 | Time: 4.73s | VRAM alloc/resv/peak(MB)=45.94/216.0/169.6 | GPU util%=100.0 | rsmi_used(MiB)=None\n",
      "Epoch [32/50] | Avg Loss: 0.0257 | Time: 4.73s | VRAM alloc/resv/peak(MB)=45.94/216.0/169.6 | GPU util%=100.0 | rsmi_used(MiB)=None\n",
      "Epoch [33/50] | Avg Loss: 0.0249 | Time: 4.99s | VRAM alloc/resv/peak(MB)=45.94/216.0/169.6 | GPU util%=100.0 | rsmi_used(MiB)=None\n",
      "Epoch [34/50] | Avg Loss: 0.0295 | Time: 4.75s | VRAM alloc/resv/peak(MB)=45.94/216.0/169.6 | GPU util%=100.0 | rsmi_used(MiB)=None\n",
      "Epoch [35/50] | Avg Loss: 0.0257 | Time: 4.99s | VRAM alloc/resv/peak(MB)=45.94/216.0/169.6 | GPU util%=100.0 | rsmi_used(MiB)=None\n",
      "Epoch [36/50] | Avg Loss: 0.0263 | Time: 4.85s | VRAM alloc/resv/peak(MB)=45.94/216.0/169.6 | GPU util%=100.0 | rsmi_used(MiB)=None\n",
      "Epoch [37/50] | Avg Loss: 0.0285 | Time: 5.01s | VRAM alloc/resv/peak(MB)=45.94/216.0/169.6 | GPU util%=100.0 | rsmi_used(MiB)=None\n",
      "Epoch [38/50] | Avg Loss: 0.0328 | Time: 4.83s | VRAM alloc/resv/peak(MB)=45.94/216.0/169.6 | GPU util%=100.0 | rsmi_used(MiB)=None\n",
      "Epoch [39/50] | Avg Loss: 0.0254 | Time: 5.03s | VRAM alloc/resv/peak(MB)=45.94/216.0/169.6 | GPU util%=100.0 | rsmi_used(MiB)=None\n",
      "Epoch [40/50] | Avg Loss: 0.0233 | Time: 4.77s | VRAM alloc/resv/peak(MB)=45.94/216.0/169.6 | GPU util%=100.0 | rsmi_used(MiB)=None\n",
      "Epoch [41/50] | Avg Loss: 0.0231 | Time: 5.03s | VRAM alloc/resv/peak(MB)=45.94/216.0/169.6 | GPU util%=100.0 | rsmi_used(MiB)=None\n",
      "Epoch [42/50] | Avg Loss: 0.0229 | Time: 4.78s | VRAM alloc/resv/peak(MB)=45.94/216.0/169.6 | GPU util%=100.0 | rsmi_used(MiB)=None\n",
      "Epoch [43/50] | Avg Loss: 0.0239 | Time: 5.02s | VRAM alloc/resv/peak(MB)=45.94/216.0/169.6 | GPU util%=100.0 | rsmi_used(MiB)=None\n",
      "Epoch [44/50] | Avg Loss: 0.0241 | Time: 4.82s | VRAM alloc/resv/peak(MB)=45.94/216.0/169.6 | GPU util%=100.0 | rsmi_used(MiB)=None\n",
      "Epoch [45/50] | Avg Loss: 0.0240 | Time: 4.96s | VRAM alloc/resv/peak(MB)=45.94/216.0/169.6 | GPU util%=100.0 | rsmi_used(MiB)=None\n",
      "Epoch [46/50] | Avg Loss: 0.0224 | Time: 5.02s | VRAM alloc/resv/peak(MB)=45.94/216.0/169.6 | GPU util%=100.0 | rsmi_used(MiB)=None\n",
      "Epoch [47/50] | Avg Loss: 0.0227 | Time: 4.80s | VRAM alloc/resv/peak(MB)=45.94/216.0/169.6 | GPU util%=100.0 | rsmi_used(MiB)=None\n",
      "Epoch [48/50] | Avg Loss: 0.0228 | Time: 5.03s | VRAM alloc/resv/peak(MB)=45.94/216.0/169.6 | GPU util%=100.0 | rsmi_used(MiB)=None\n",
      "Epoch [49/50] | Avg Loss: 0.0227 | Time: 5.04s | VRAM alloc/resv/peak(MB)=45.94/216.0/169.6 | GPU util%=100.0 | rsmi_used(MiB)=None\n",
      "Epoch [50/50] | Avg Loss: 0.0237 | Time: 5.04s | VRAM alloc/resv/peak(MB)=45.94/216.0/169.6 | GPU util%=100.0 | rsmi_used(MiB)=None\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "hidden_size = 256\n",
    "encoder = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
    "decoder = DecoderRNN(hidden_size, output_lang.n_words).to(device)\n",
    "\n",
    "learning_rate = 0.0005\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "num_epochs = 50\n",
    "print_every = 1\n",
    "plot_losses = []\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    t0 = time.time()\n",
    "    total_loss = 0\n",
    "\n",
    "    for pair in pairs:\n",
    "        input_tensor, target_tensor = tensorsFromPair(pair)\n",
    "        input_tensor, target_tensor = input_tensor.to(device), target_tensor.to(device)\n",
    "\n",
    "        loss = train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        total_loss += loss\n",
    "\n",
    "    epoch_time = time.time() - t0\n",
    "    avg_loss = total_loss / len(pairs)\n",
    "    plot_losses.append(avg_loss)  # keep track of loss per epoch\n",
    "\n",
    "    rsmi = rocm_query_util_and_vram()\n",
    "\n",
    "    print(\n",
    "        f\"Epoch [{epoch}/{num_epochs}] \"\n",
    "        f\"| Avg Loss: {avg_loss:.4f} \"\n",
    "        f\"| Time: {epoch_time:.2f}s \"\n",
    "        f\"| GPU util%={rsmi['util_percent']} \"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dybVgMTS2tz",
   "metadata": {
    "id": "5dybVgMTS2tz"
   },
   "source": [
    "### Evaluation Function\n",
    "\n",
    "This function runs the trained Seq2Seq model in inference mode to translate an English input sentence into a Chinese output.\n",
    "\n",
    "It first converts the input sentence into a tensor and passes it through the encoder to obtain the hidden state. This hidden state is then used by the decoder to generate the translation one word at a time.\n",
    "\n",
    "At each decoding step, the decoder predicts a probability distribution over the output vocabulary. The word with the highest probability is selected (via `topk(1)`) and used as the input for the next step. This continues until the model predicts the `EOS_token` or reaches the maximum sequence length.\n",
    "\n",
    "The function returns the translated output as a space-separated string of Chinese tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "gwVSM_uvS3KC",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1754809389822,
     "user": {
      "displayName": "LIAO FLORA",
      "userId": "18011015488649422122"
     },
     "user_tz": -480
    },
    "id": "gwVSM_uvS3KC",
    "outputId": "211671b0-2b12-47ed-d881-ef47acf61513"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你叫什么来着\n"
     ]
    }
   ],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=20):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence).to(device)\n",
    "        input_length = input_tensor.size(0)\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "\n",
    "            token_id = topi.item()\n",
    "            if token_id == EOS_token:\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(output_lang.index2word[token_id])\n",
    "\n",
    "            decoder_input = topi.detach().view(1, 1).to(device)\n",
    "\n",
    "        return \" \".join(decoded_words)\n",
    "\n",
    "\n",
    "# Test example\n",
    "print(evaluate(encoder, decoder, \"what is your name\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "BqtFl4t7S5Ve",
   "metadata": {
    "id": "BqtFl4t7S5Ve"
   },
   "source": [
    "### Results & Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "OPcBxDtmS8OY",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "executionInfo": {
     "elapsed": 428,
     "status": "ok",
     "timestamp": 1754809390247,
     "user": {
      "displayName": "LIAO FLORA",
      "userId": "18011015488649422122"
     },
     "user_tz": -480
    },
    "id": "OPcBxDtmS8OY",
    "outputId": "5c7f8c5a-17ca-4b49-aca9-f8bc79369788"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(plot_losses)\n",
    "plt.title(\"Training Loss\")\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0085068-691a-4368-ae34-61745459a125",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (ROCm miniforge3 3.12)",
   "language": "python",
   "name": "rocm-py312"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
