{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fb27b941602401d91542211134fc71a",
   "metadata": {},
   "source": [
    "Copyright (C) 2025 Advanced Micro Devices, Inc. All rights reserved.\n",
    "Portions of this notebook consist of AI-generated content.\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "\n",
    "of this software and associated documentation files (the \"Software\"), to deal\n",
    "\n",
    "in the Software without restriction, including without limitation the rights\n",
    "\n",
    "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "\n",
    "copies of the Software, and to permit persons to whom the Software is\n",
    "\n",
    "furnished to do so, subject to the following conditions:\n",
    "\n",
    "\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all\n",
    "\n",
    "copies or substantial portions of the Software.\n",
    "\n",
    "\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "\n",
    "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "\n",
    "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "\n",
    "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "\n",
    "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "\n",
    "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "\n",
    "SOFTWARE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jJZqNRIUJ4yw",
   "metadata": {
    "id": "jJZqNRIUJ4yw"
   },
   "source": [
    "# DL08 Basic CNN\n",
    "### Lab Description\n",
    "This laboratory exercise introduces **Convolutional Neural Networks (CNNs)**, a foundational deep learning architecture widely used for image classification tasks. CNNs are specifically designed to process and learn from visual data by capturing spatial hierarchies in images through convolutional filters.\n",
    "\n",
    "In this hands-on lab, you will use the ``CIFAR-10`` dataset to build and train a basic CNN for multi-class image classification. You will explore model construction, training loops, and evaluation techniques to better understand the workflow of applying CNNs to real-world datasets.\n",
    "\n",
    "### What you can expect to learn\n",
    "- Model Architecture: Understand the structure and components of a basic CNN (convolution, pooling, fully connected layers).\n",
    "\n",
    "- Data Preprocessing: Learn to prepare and normalize image data for deep learning models.\n",
    "\n",
    "- Model Training and Evaluation: Gain hands-on experience training a CNN using PyTorch, monitoring performance, and testing on unseen data.\n",
    "\n",
    "- Visualization: Visualize sample predictions to assess model performance qualitatively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "VbCecuMlKKQz",
   "metadata": {
    "id": "VbCecuMlKKQz"
   },
   "source": [
    "### Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8e5e43-6480-4299-a898-02c8ae6cb241",
   "metadata": {
    "executionInfo": {
     "elapsed": 12013,
     "status": "ok",
     "timestamp": 1754748811571,
     "user": {
      "displayName": "LIAO FLORA",
      "userId": "18011015488649422122"
     },
     "user_tz": -480
    },
    "id": "dc8e5e43-6480-4299-a898-02c8ae6cb241"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"device: {device}\")\n",
    "print(\"GPU Name:\", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8Q43OXcKSla",
   "metadata": {
    "id": "f8Q43OXcKSla"
   },
   "source": [
    "### Required Dataset\n",
    "In this section, we load the ``CIFAR-10`` dataset and apply necessary transformations.\n",
    "Each image in CIFAR-10 is a 32x32 color image belonging to one of 10 classes.\n",
    "We normalize the pixel values to fall within the range [-1, 1] for better training stability.\n",
    "The dataset is then split into a training set and a test set, and data loaders are prepared for efficient batch processing during training and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "-DNhHZQ_KUb3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3568,
     "status": "ok",
     "timestamp": 1754748815148,
     "user": {
      "displayName": "LIAO FLORA",
      "userId": "18011015488649422122"
     },
     "user_tz": -480
    },
    "id": "-DNhHZQ_KUb3",
    "outputId": "5d471624-965e-4019-948a-16d838543804"
   },
   "outputs": [],
   "source": [
    "# Define image transformations\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761))]\n",
    ")\n",
    "\n",
    "# Download CIFAR-10 training and test sets\n",
    "DATA_ROOT = os.path.expanduser(\"~/data/cifar10\")\n",
    "os.makedirs(DATA_ROOT, exist_ok=True)\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root=DATA_ROOT, train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root=DATA_ROOT, train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False, num_workers=2)\n",
    "\n",
    "# Classes in CIFAR-10 Dataset\n",
    "classes = trainset.classes\n",
    "len(classes), classes[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "mx5C02lwKtSt",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 165
    },
    "executionInfo": {
     "elapsed": 422,
     "status": "ok",
     "timestamp": 1754748815572,
     "user": {
      "displayName": "LIAO FLORA",
      "userId": "18011015488649422122"
     },
     "user_tz": -480
    },
    "id": "mx5C02lwKtSt",
    "outputId": "ac101617-92dc-4045-a7d2-ba085e27e721"
   },
   "outputs": [],
   "source": [
    "# Visualize some training images\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5  # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# Show images\n",
    "imshow(torchvision.utils.make_grid(images[:8]))\n",
    "# Print labels\n",
    "print(\" \".join(f\"{classes[labels[j]]:5s}\" for j in range(8)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Xd5F_YbMK6Ug",
   "metadata": {
    "id": "Xd5F_YbMK6Ug"
   },
   "source": [
    "### Define a Simple CNN Model\n",
    "In this section, we define a simple Convolutional Neural Network (CNN) using PyTorchâ€™s nn.Module.\n",
    "The model consists of two convolutional layers followed by ReLU activation and max pooling to downsample feature maps.\n",
    "The resulting features are then flattened and passed through fully connected layers for classification into one of the 100 CIFAR-100 classes.\n",
    "This basic architecture is sufficient for demonstrating key concepts in CNN-based image classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TX11coL5LBB6",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1754748815576,
     "user": {
      "displayName": "LIAO FLORA",
      "userId": "18011015488649422122"
     },
     "user_tz": -480
    },
    "id": "TX11coL5LBB6"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class BasicCNN(nn.Module):\n",
    "    def __init__(self, num_classes=10, p_drop=0.25):\n",
    "        super().__init__()\n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)  # 3 -> 32\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)  # 32 -> 64\n",
    "\n",
    "        # Pooling\n",
    "        self.pool = nn.MaxPool2d(2, 2)  # 32->16->8\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(64 * 8 * 8, 512)\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "\n",
    "        # Regularization\n",
    "        self.dropout = nn.Dropout(p_drop)\n",
    "\n",
    "        # Init\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        # [B,3,32,32] -> [B,32,32,32] -> [B,32,16,16]\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        # [B,64,16,16] -> [B,64,8,8]\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        # Flatten: [B, 64*8*8]\n",
    "        x = x.view(x.size(0), -1)\n",
    "        # FC + dropout -> logits [B, num_classes]\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tcWxk4r8LF7G",
   "metadata": {
    "id": "tcWxk4r8LF7G"
   },
   "source": [
    "### Training\n",
    "In this part, we initialize the CNN model, define the loss function (CrossEntropyLoss for multi-class classification), and choose the optimizer (Adam) with a learning rate of 0.001.\n",
    "\n",
    "We then train the model using the training data.\n",
    "Each batch of images is passed through the model, the loss is computed, and backpropagation is performed to update the weights.\n",
    "The training loss is printed every 100 mini-batches to monitor progress.\n",
    "The model is trained using a GPU if available for faster computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Lf6DJ8sWLMPq",
   "metadata": {
    "id": "Lf6DJ8sWLMPq",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import re\n",
    "\n",
    "import torch\n",
    "\n",
    "model = BasicCNN(num_classes=10).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "CKPT_DIR = os.path.expanduser(\"~/data/cnn_ckpt\")\n",
    "os.makedirs(CKPT_DIR, exist_ok=True)\n",
    "\n",
    "\n",
    "def find_latest_ckpt(ckpt_dir: str):\n",
    "    pattern = re.compile(r\"epoch_(\\d+)\\.pth$\")\n",
    "    epoch_ckpts = []\n",
    "    for p in glob.glob(os.path.join(ckpt_dir, \"epoch_*.pth\")):\n",
    "        m = pattern.search(os.path.basename(p))\n",
    "        if m:\n",
    "            epoch_ckpts.append((int(m.group(1)), p))\n",
    "    if epoch_ckpts:\n",
    "        epoch_ckpts.sort()\n",
    "        return epoch_ckpts[-1][1]\n",
    "    last_p = os.path.join(ckpt_dir, \"last.pth\")\n",
    "    return last_p if os.path.exists(last_p) else None\n",
    "\n",
    "\n",
    "start_epoch = 0\n",
    "train_loss_per_epoch = []\n",
    "\n",
    "latest = find_latest_ckpt(CKPT_DIR)\n",
    "if latest:\n",
    "    print(f\"[resume] loading ckpt: {latest}\")\n",
    "    ckpt = torch.load(latest, map_location=\"cpu\")\n",
    "    try:\n",
    "        model.load_state_dict(ckpt[\"model_state\"])\n",
    "        optimizer.load_state_dict(ckpt[\"optimizer_state\"])\n",
    "        for state in optimizer.state.values():\n",
    "            for k, v in state.items():\n",
    "                if torch.is_tensor(v):\n",
    "                    state[k] = v.to(device)\n",
    "        start_epoch = int(ckpt.get(\"epoch\", 0))\n",
    "        if \"train_loss\" in ckpt:\n",
    "            print(f\"[resume] previous loss: {ckpt['train_loss']:.6f}\")\n",
    "        print(f\"[resume] start from epoch {start_epoch + 1}\")\n",
    "    except Exception as e:\n",
    "        print(f\"[resume] failed to load state dicts: {e}\\n[resume] training from scratch.\")\n",
    "\n",
    "# Training loop\n",
    "EPOCHS = 10\n",
    "train_loss_per_epoch = []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    running_loss = 0.0\n",
    "    for i, (inputs, labels) in enumerate(trainloader, 0):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    epoch_loss = running_loss / len(trainloader)\n",
    "    train_loss_per_epoch.append(epoch_loss)\n",
    "\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        print(f\"Epoch [{epoch + 1}/{EPOCHS}] Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        ckpt_path = os.path.join(CKPT_DIR, f\"epoch_{epoch + 1:03d}.pth\")\n",
    "        torch.save(\n",
    "            {\n",
    "                \"epoch\": epoch + 1,\n",
    "                \"model_state\": model.state_dict(),\n",
    "                \"optimizer_state\": optimizer.state_dict(),\n",
    "                \"train_loss\": epoch_loss,\n",
    "                \"arch\": model.__class__.__name__,\n",
    "                \"lr\": optimizer.param_groups[0][\"lr\"],\n",
    "            },\n",
    "            ckpt_path,\n",
    "        )\n",
    "        print(f\"[ckpt] saved: {ckpt_path}\")\n",
    "\n",
    "print(\"Finished Training\")\n",
    "\n",
    "final_path = os.path.join(CKPT_DIR, \"last.pth\")\n",
    "torch.save(\n",
    "    {\n",
    "        \"epoch\": EPOCHS,\n",
    "        \"model_state\": model.state_dict(),\n",
    "        \"optimizer_state\": optimizer.state_dict(),\n",
    "        \"train_loss\": train_loss_per_epoch[-1],\n",
    "        \"arch\": model.__class__.__name__,\n",
    "        \"lr\": optimizer.param_groups[0][\"lr\"],\n",
    "    },\n",
    "    final_path,\n",
    ")\n",
    "print(f\"[ckpt] saved last: {final_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "AFnib--KLxEG",
   "metadata": {
    "id": "AFnib--KLxEG"
   },
   "outputs": [],
   "source": [
    "# Plot the training loss curve\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(range(1, EPOCHS + 1), train_loss_per_epoch, marker=\"o\", label=\"Training Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training Loss Curve\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "RxA374oMLJpr",
   "metadata": {
    "id": "RxA374oMLJpr"
   },
   "source": [
    "### Results & Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "k8HmWZGxLpYf",
   "metadata": {
    "id": "k8HmWZGxLpYf"
   },
   "outputs": [],
   "source": [
    "# Evaluate on test data\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in testloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy on 10,000 test images: {100 * correct / total:.2f}%\")\n",
    "\n",
    "# Show some predictions\n",
    "dataiter = iter(testloader)\n",
    "images, labels = next(dataiter)\n",
    "images, labels = images.to(device), labels.to(device)\n",
    "outputs = model(images)\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "imshow(torchvision.utils.make_grid(images[:8].cpu()))\n",
    "print(\"GroundTruth: \", \" \".join(f\"{classes[labels[j]]:5s}\" for j in range(8)))\n",
    "print(\"Predicted:   \", \" \".join(f\"{classes[predicted[j]]:5s}\" for j in range(8)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee4ad79-2d75-45bf-9685-0e6c13151c1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
